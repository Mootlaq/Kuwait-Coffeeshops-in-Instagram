{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Motlaq Almajhool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from googletrans import Translator\n",
    "from emoji import demojize\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function:  Create Dataframe from Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info(data):\n",
    "\n",
    "    types = []\n",
    "    like_counts = []\n",
    "    post_captions = []\n",
    "    comments_counts = []\n",
    "    idds = []\n",
    "    usernames = []\n",
    "    comments_content = []\n",
    "    comment_user = []\n",
    "\n",
    "    for image in data['GraphImages']:\n",
    "        comments_folder = image['comments']['data']\n",
    "        #try:\n",
    "        if len(comments_folder) > 0:\n",
    "            comments = []\n",
    "            #n_comments = len(comments_folder)\n",
    "            for i in range(len(comments_folder)):\n",
    "                #comments.append(comments_folder[i]['text'])\n",
    "                comments_content.append(comments_folder[i]['text'])\n",
    "                comment_user.append(comments_folder[i]['owner']['username'])\n",
    "                types.append(image['__typename'])\n",
    "                like_counts.append(image['edge_media_preview_like']['count'])\n",
    "                try:\n",
    "                    post_captions.append(image['edge_media_to_caption']['edges'][0]['node']['text'])\n",
    "                except:\n",
    "                    post_captions.append('no caption')\n",
    "                comments_counts.append(image['edge_media_to_comment']['count'])      \n",
    "                idds.append(image['id'])\n",
    "                usernames.append(image['username'])\n",
    "        else:\n",
    "            comments_content.append('no comment')\n",
    "            types.append(image['__typename'])\n",
    "            like_counts.append(image['edge_media_preview_like']['count'])\n",
    "            try:\n",
    "                post_captions.append(image['edge_media_to_caption']['edges'][0]['node']['text'])\n",
    "            except:\n",
    "                post_captions.append('no caption')\n",
    "            comments_counts.append(image['edge_media_to_comment']['count'])      \n",
    "            idds.append(image['id'])\n",
    "            usernames.append(image['username'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.DataFrame([usernames, post_captions, like_counts, comments_counts, comments_content, comment_user, types, idds])\n",
    "    columns = ['usernames', 'post_captions', 'like_counts', 'comments_counts', 'comments_content', 'comment_user', 'types', 'id']\n",
    "    df = df.T\n",
    "    df.columns = columns\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and count posts' languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_posts_langs(df):\n",
    "    arabic = 0\n",
    "    english = 0\n",
    "    words_language = []\n",
    "    post_language = []\n",
    "    emoji_maybe = 0\n",
    "    dfposts = df.drop_duplicates(subset=['id'])\n",
    "    for post in dfposts['post_captions']:\n",
    "        #print(post)\n",
    "        post = demojize(post)\n",
    "        post = re.sub(r':.+?:', '', post)\n",
    "        words = []\n",
    "        for word in post.split(' '):\n",
    "            word = re.sub(r'(#[A-Za-z0-9_.]+)', '', word)\n",
    "            words.append(word)\n",
    "        post = ' '.join(word for word in words)\n",
    "        translator = Translator()\n",
    "        detect_lang = translator.detect(post)\n",
    "        #time.sleep(15)\n",
    "        if detect_lang.confidence == 0.0 and detect_lang.lang == 'en':\n",
    "            post_language.append('Emjoi or No Caption')\n",
    "        else:\n",
    "            post_language.append(detect_lang.lang)\n",
    "    posts_languages_count = Counter(post_language)\n",
    "#    arabic_posts_percent = (posts_languages_count['ar']/len(dfposts))*100\n",
    "\n",
    "    emoji_posts = posts_languages_count['Emjoi or No Caption']\n",
    "    del posts_languages_count['Emjoi or No Caption']\n",
    "    sumlang = sum(posts_languages_count.values())\n",
    "    ar_percent = (posts_languages_count['ar']/sumlang)*100\n",
    "    \n",
    "    \n",
    "    return ar_percent, posts_languages_count, emoji_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and count comments' languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_comments_langs(df):\n",
    "    from emoji import demojize\n",
    "    words_language = []\n",
    "    post_language = []\n",
    "    \n",
    "    for comment in df.sample(200)['comments_content']:\n",
    "        comment = demojize(comment)\n",
    "        comment = re.sub(r'@([A-Za-z0-9_.]+)', '', comment)\n",
    "        comment = re.sub(r':.+?:', '', comment)\n",
    "        #comment = re.sub(r'[-$()\\\"#/@;:<>{&*}`+=~^|.!?,]', '', comment)\n",
    "        comment = re.sub(r'[0-9]', '',comment)\n",
    "        comment = re.sub(r'[٠-٩]', '',comment)\n",
    "        translator = Translator()\n",
    "        detect_lang = translator.detect(comment)\n",
    "        if detect_lang.confidence == 0.0 and detect_lang.lang == 'en':\n",
    "            post_language.append('Emjoi or No Caption')\n",
    "        else:\n",
    "            post_language.append(detect_lang.lang)\n",
    "#         print(\"---------\")\n",
    "#         print(\"Comment:\")\n",
    "#         print(comment)\n",
    "#         print(detect_lang.lang)\n",
    "#         print(detect_lang.confidence)\n",
    "    comments_languages_count = Counter(post_language)\n",
    "    emoji_comments = comments_languages_count['Emjoi or No Caption']\n",
    "    del comments_languages_count['Emjoi or No Caption']\n",
    "    sumlang = sum(comments_languages_count.values())\n",
    "    ar_percent = (comments_languages_count['ar']/sumlang)*100\n",
    "    \n",
    "    #arabic_comments_percent = (comments_languages_count['ar']/len(df.sample(200)['comments_content']))*100\n",
    "    return ar_percent, comments_languages_count, emoji_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/motlaq/ig2/tobysestatekw.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrape_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_count, posts_languages, emoji_posts = count_posts_langs(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(60) #Google Cloud API, you suck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_comments, comments_languages, emoji_comments = count_comments_langs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.476190476190474\n",
      "66.22516556291392\n"
     ]
    }
   ],
   "source": [
    "print(languages_count) \n",
    "print(ar_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'en': 50, 'ar': 34})\n",
      "Counter({'ar': 100, 'en': 45, 'sd': 3, 'arfa': 1, 'ceb': 1, 'ja': 1})\n",
      "0\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(posts_languages)\n",
    "print(comments_languages)\n",
    "print(emoji_posts)\n",
    "print(emoji_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### The code below is similar the functions we used already. Only difference is that this code returns a dataframe with columns that show the language of each observation (post/comment). Maybe I should've used this code in the first place. Anyway, This code was used in the notebook 'Analysing specific coffeeshops' which I used to get analyse specific coffeeshops (The last part of the article where I talked about.) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_post(post):\n",
    "    post = demojize(post)\n",
    "    post = re.sub(r':.+?:', '', post)\n",
    "    words = []\n",
    "    for word in post.split(' '):\n",
    "        word = re.sub(r'(#[A-Za-z0-9_.]+)', '', word)\n",
    "        words.append(word)\n",
    "    post = ' '.join(word for word in words)\n",
    "    translator = Translator()\n",
    "    detect_lang = translator.detect(post)\n",
    "        #time.sleep(15)\n",
    "    if detect_lang.confidence == 0.0 and detect_lang.lang == 'en':\n",
    "        lang = 'Emoji or No Caption'\n",
    "    else:\n",
    "        lang = detect_lang.lang\n",
    "    return lang\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_comment(comment):\n",
    "    comment = demojize(comment)\n",
    "    comment = re.sub(r'@([A-Za-z0-9_.]+)', '', comment)\n",
    "    comment = re.sub(r':.+?:', '', comment)\n",
    "    #comment = re.sub(r'[-$()\\\"#/@;:<>{&*}`+=~^|.!?,]', '', comment)\n",
    "    comment = re.sub(r'[0-9]', '',comment)\n",
    "    comment = re.sub(r'[٠-٩]', '',comment)\n",
    "    translator = Translator()\n",
    "    detect_lang = translator.detect(comment)\n",
    "    if detect_lang.confidence == 0.0 and detect_lang.lang == 'en':\n",
    "        lang = 'Emjoi or No Caption'\n",
    "    else:\n",
    "        lang = detect_lang.lang\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/motlaq/ig2/tobysestatekw.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdf_withlang(data):\n",
    "    df = scrape_info(data)\n",
    "    postlang = []\n",
    "    cmntlang = []\n",
    "    for row in df.itertuples():\n",
    "        post = row.post_captions\n",
    "        cmnt = row.comments_content\n",
    "        #index = row.Index\n",
    "        post_lang = detect_post(post)\n",
    "        time.sleep(5)\n",
    "        cmnt_lang = detect_comment(cmnt)\n",
    "        postlang.append(post_lang)\n",
    "        cmntlang.append(cmnt_lang)\n",
    "    df['post_lang'] = postlang\n",
    "    df['comment_lang'] = cmntlang\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createdf_withlang(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tobys.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
